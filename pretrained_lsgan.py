# -*- coding: utf-8 -*-
"""Pretrain.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14Pyd7mK2ppqyrysscfNSikOCCM2Wofui
"""

!nvidia-smi

import random
import torch
import numpy as np
from pathlib import Path

import torch.nn.parallel
import torch.backends.cudnn as cudnn
from torch.utils.data import DataLoader, Dataset, SubsetRandomSampler
import torchvision.datasets as dset
import torchvision.transforms as transforms

import matplotlib.pyplot as plt
import shutil

import glob
import os
from PIL import Image

import torch.nn as nn 
import torch.nn.functional as F

import torch.optim as optim
from torch.autograd import Variable
import imageio

seed = 123
random.seed(seed)
torch.manual_seed(seed)
np.random.seed(seed)
print("My seed:", seed)

DATA_PATH = Path('./data')
PATH = DATA_PATH / 'celeba'
PATH.mkdir(parents=True, exist_ok=True)

# Number of worker threads
workers = 2 # 2 cores available in colab

# Batch size
b_size = 128

# Spatial size of the training images. Resize to this size
image_size = 64

# Number of channels (Here it's 3 since RGB images)
nc = 3

# Size of latent vector
nz = 100

# Size of feature maps in generator
ngf = 64

# Size of feature maps in discriminator
ndf = 64

# Number of training epocs
num_epochs = 5

# Number of GPUs available. Use 0 for CPU mode.
ngpu = 1

# Important! The following line sets the device.
device = torch.device("cuda:0" if (torch.cuda.is_available() and ngpu > 0) else "cpu")

# Length of dataset
d_len = 202599

"""## Data"""

!wget https://s3-us-west-1.amazonaws.com/udacity-dlnfd/datasets/celeba.zip

from google.colab import drive
drive.mount('/content/drive')

!cp ./celeba.zip ./data/celeba

!unzip ./data/celeba/celeba.zip -d {PATH}

!ls {PATH/'img_align_celeba'} | wc -l

random.seed(seed)
torch.manual_seed(seed)
np.random.seed(seed)

noise_set = torch.randn(202599, nz, 1, 1, device=device)

"""## Creating fixed Gaussian noise"""

noise_set.mean(), noise_set.var(), noise_set[345].mean()

"""## Creating datasets"""

class NoiseImageDataset(Dataset):
  def __init__(self, root, noise_set, transforms_=None):
    self.transform = transforms.Compose(transforms_)
    self.noise_set = noise_set
    
    self.files = sorted(glob.glob(os.path.join(root) + '/*.*'))
    self.len = len(self.files)
    
  def __getitem__(self, index):
    
    item = self.transform(Image.open(self.files[index % self.len]))
    
    noise = self.noise_set[index % self.len]
      
    return {'x': noise, 'y': item}
  
  def __len__(self):
    return self.len

dataset = NoiseImageDataset(root=PATH/'img_align_celeba',
                           noise_set=noise_set,
                           transforms_=[
                               transforms.Resize(image_size),
                               transforms.CenterCrop(image_size),
                               transforms.ToTensor(),
                               transforms.Normalize((.5,.5,.5), (.5,.5,.5)),
                           ])

dataloader = DataLoader(dataset, batch_size=b_size, 
                        shuffle=True, num_workers=0)

import matplotlib.pyplot as plt
import numpy as np
import torchvision.utils as vision_utils

real_batch = next(iter(dataloader))
plt.figure(figsize=(8,8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vision_utils.make_grid(real_batch['y'].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))

"""## Models"""

def weights_init_normal(m):
    classname = m.__class__.__name__
    if classname.find('Conv') != -1:
        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)
    elif classname.find('BatchNorm2d') != -1:
        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)
        torch.nn.init.constant_(m.bias.data, 0.0)

class SigmoidLayer(nn.Module):
  def __init__(self):
    super(SigmoidLayer, self).__init__()
    self.model = nn.Sequential(nn.Sigmoid())
    
  def forward(self, x):
    return self.model(x)

class GeneratorTemp(nn.Module):
  def __init__(self, in_channels, out_channels):
    super(GeneratorTemp, self).__init__()
    
    model = [
              nn.Conv2d(in_channels, out_channels, 3, stride=1, padding=1),
              nn.Tanh()
            ]
    
    self.model = nn.Sequential(*model)
    
  def forward(self, x):
    return self.model(x)

class DiscriminatorTemp(nn.Module):
  def __init__(self, in_channels, out_channels):
    super(DiscriminatorTemp, self).__init__()
    
    model = [
              nn.Conv2d(in_channels, out_channels, 3, stride=1, padding=1),
              nn.BatchNorm2d(out_channels),
              nn.LeakyReLU(0.2, inplace=True),
            ]
    
    self.model = nn.Sequential(*model)
    
  def forward(self, x):
    return self.model(x)

class GeneratorBlock(nn.Module):
  def __init__(self, in_channels, out_channels):
    super(GeneratorBlock, self).__init__()
    
    model = [
              nn.ConvTranspose2d(in_channels, out_channels, 4, stride=2, padding=1, bias=False),
              nn.BatchNorm2d(out_channels),
              nn.ReLU(True),
              nn.Conv2d(out_channels, out_channels, 3, stride=1, padding=1),
              nn.BatchNorm2d(out_channels),
              nn.ReLU(True),
            ]
    
    self.model = nn.Sequential(*model)
    
  def forward(self, x):
    return self.model(x)

class DiscriminatorBlock(nn.Module):
  def __init__(self, in_channels, out_channels):
    super(DiscriminatorBlock, self).__init__()
    
    model = [
              nn.Conv2d(in_channels, out_channels, 4, stride=2, padding=1),
              nn.BatchNorm2d(out_channels),
              nn.LeakyReLU(0.2, inplace=True),
              nn.Conv2d(out_channels, out_channels, 3, stride=1, padding=1),
              nn.BatchNorm2d(out_channels),
              nn.LeakyReLU(0.2, inplace=True),
            ]
    
    self.model = nn.Sequential(*model)
    
  def forward(self, x):
    return self.model(x)

class Generator(nn.Module):
  def __init__(self):
    super(Generator, self).__init__()    
    model = [
              nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),
              nn.BatchNorm2d(ngf * 8),
              nn.ReLU(True),
              nn.Conv2d(ndf * 8, ndf * 8, 3, stride=1, padding=1),
              nn.BatchNorm2d(ngf * 8),
              nn.ReLU(True),
            ]
    self.model = nn.Sequential(*model)
    
  def forward(self, x):
    return self.model(x)

class Discriminator(nn.Module):
  def __init__(self):
    super(Discriminator, self).__init__()    
    model = [
              nn.Conv2d(ndf * 8, ndf * 8, 3, 1, 1, bias=False),
              nn.BatchNorm2d(ndf * 8),
              nn.LeakyReLU(0.2, inplace=True),
              nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),
            ]
    self.model = nn.Sequential(*model)
    
  def forward(self, x):
    return self.model(x)

def initG(out_channels):
  netG = Generator().to(device)
  netG.apply(weights_init_normal)
  
  G_temp = GeneratorTemp(ngf * 8, out_channels).to(device)
  G_temp.apply(weights_init_normal)
  
  return nn.Sequential(netG, G_temp)

def addGenLayer(netG, in_channels, out_channels):
  G_layer = GeneratorBlock(in_channels, out_channels).to(device)
  G_layer.apply(weights_init_normal)
  removed = nn.Sequential(*list(netG.children())[:-1])
  
  G_temp = GeneratorTemp(out_channels, nc).to(device)
  G_temp.apply(weights_init_normal)
  
  return nn.Sequential(removed, G_layer, G_temp)

def initD(in_channels):
  D_temp = DiscriminatorTemp(in_channels, ndf * 8).to(device)
  D_temp.apply(weights_init_normal)
  
  netD = Discriminator().to(device)
  netD.apply(weights_init_normal)
  
  sig = SigmoidLayer().to(device)
  sig.apply(weights_init_normal)
  
  return nn.Sequential(D_temp, netD)

def addDisLayer(netD, in_channels, out_channels):
  D_layer = DiscriminatorBlock(in_channels, out_channels).to(device)
  D_layer.apply(weights_init_normal)
  removed = nn.Sequential(*list(netD.children())[1:])
  
  D_temp = DiscriminatorTemp(nc, in_channels).to(device)
  D_temp.apply(weights_init_normal)
  
  return nn.Sequential(D_temp, D_layer, removed)

class Critic(nn.Module):
  def __init__(self, ngpu):
    super(Critic, self).__init__()
    self.ngpu = ngpu
    self.main = nn.Sequential(
      nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),
      nn.LeakyReLU(0.2, inplace=True),
        
      nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),
      nn.BatchNorm2d(ndf * 2),
      nn.LeakyReLU(0.2, inplace=True),
        
      nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),
      nn.BatchNorm2d(ndf * 4),
      nn.LeakyReLU(0.2, inplace=True),
        
      nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),
      nn.BatchNorm2d(ndf * 8),
      nn.LeakyReLU(0.2, inplace=True),
        
      nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),
    )
    
  def forward(self, input):
    return self.main(input).view(-1)

# Create the critic
netD = Critic(ngpu).to(device)
netD.apply(weights_init_normal)
print(netD)

"""# Training

## 4x4 Images (Generator)

### Models
"""

netG = initG(3)
print(netG)

"""### Dataloader"""

random.seed(seed)
torch.manual_seed(seed)
np.random.seed(seed)

dataset = NoiseImageDataset(root=PATH/'img_align_celeba',
                           noise_set=noise_set,
                           transforms_=[
                               transforms.Resize(image_size // 16),
                               transforms.CenterCrop(image_size // 16),
                               transforms.ToTensor(),
                               transforms.Normalize((.5,.5,.5), (.5,.5,.5)),
                           ])

dataloader = DataLoader(dataset, batch_size=b_size, 
                        shuffle=True, num_workers=0)

real_batch = next(iter(dataloader))
plt.figure(figsize=(8,8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vision_utils.make_grid(real_batch['y'].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))

"""### Loss and other parameters"""

criterion = nn.L1Loss()

lr = 1e-3
n_epochs = 10
optimizer_G = optim.Adam(netG.parameters(), lr=lr, betas=(0.5, 0.999))
# optimizer_D = optim.Adam(netD.parameters(), lr=lr, betas=(0.5, 0.999))

"""### Memory Allocations"""

G_losses = []
Tensor = torch.cuda.FloatTensor
target = Tensor(b_size, 3, image_size//16, image_size//16)
# input_B = Tensor(b_size, 3, image_size//16, image_size//16)

target_real = Variable(Tensor(b_size).fill_(1.), requires_grad=False)
target_fake = Variable(Tensor(b_size).fill_(0.), requires_grad=False)

"""### Load Model"""

checkpoint = torch.load('./drive/My Drive/preG-final.pth')
netG.load_state_dict(checkpoint['model_state_dict'])
optimizer_G.load_state_dict(checkpoint['optimizer_state_dict'])
epoch = checkpoint['epoch']

netG.train()

import os
import shutil

for e in range(0 , n_epochs):
  for i, batch in enumerate(dataloader):
    
    if(batch['y'].shape[0] != b_size):
      continue

    # Set model inputs
    target_img = Variable(target.copy_(batch['y']))
    inp = batch['x']
    
    optimizer_G.zero_grad()
    
    # L1 Loss
    fake_img = netG(inp)
    loss_G = criterion(fake_img, target_img)
    loss_G.backward()
    
    optimizer_G.step()
    
    
    # Output training stats
    if i % 50 == 0:
        print('[%d/%d][%d/%d]\tLoss_G: %.4f'
#               % (e, n_epochs, i, len(dataloader),
                 loss_G.item()))

    # Save Losses for plotting later
    G_losses.append(loss_G.item())
  
  if e % 5 == 0:
    torch.save({
            'epoch': e,
            'model_state_dict':netG.state_dict(),
            'optimizer_state_dict': optimizer_G.state_dict(),
            }, "./drive/My Drive/preG-{}.pth".format(e))

torch.save({
        'epoch': e,
        'model_state_dict':netG.state_dict(),
        'optimizer_state_dict': optimizer_G.state_dict(),
        }, "./drive/My Drive/preG-final.pth".format(e))

"""## 4x4 Images (Discriminator)

### Sampling Images
"""

random.seed(seed)
torch.manual_seed(seed)
np.random.seed(seed)

# Sampling fake images
fake_samples = []
for i in range(1, d_len + 1):
  fixed_noise = noise_set[i-1]
  fake = netG(fixed_noise.unsqueeze(0)).detach().cpu().numpy()
  fake_samples.append(fake.squeeze(0))
  if i % 50000 == 0:
    print(i)

"""### Discriminator Dataloader"""

class DiscrimDataset(Dataset):
  def __init__(self, root, fake_samples, transforms_=None):
    self.transform = transforms.Compose(transforms_)
    
    self.files = sorted(glob.glob(os.path.join(root) + '/*.*'))
    self.fake_samples = fake_samples
    self.len = len(fake_samples)
    
  def __getitem__(self, index):
    rand = np.random.random_sample()
    if rand >= 0.5:
      item = self.transform(Image.open(self.files[index % self.len]))
      return {'x': item, 'y': 1}
    else:
      item = torch.from_numpy(self.fake_samples[index % self.len])
      return {'x': item, 'y': 0}
    
  
  def __len__(self):
    return self.len

dataset = DiscrimDataset(root=PATH/'img_align_celeba',
                           fake_samples=fake_samples,
                           transforms_=[
                               transforms.Resize(image_size // 16),
                               transforms.CenterCrop(image_size // 16),
                               transforms.ToTensor(),
                               transforms.Normalize((.5,.5,.5), (.5,.5,.5)),
                           ])

random.seed(seed)
torch.manual_seed(seed)
np.random.seed(seed)

# train validation split
validation_split = 0.1

dataset_len = len(dataset)
indices = list(range(dataset_len))

# Randomly splitting indices:
val_len = int(np.floor(validation_split * dataset_len))
validation_idx = np.random.choice(indices, size=val_len, replace=False)
train_idx = list(set(indices) - set(validation_idx))

# Samplers
train_sampler = SubsetRandomSampler(train_idx)
validation_sampler = SubsetRandomSampler(validation_idx)

# DataLoader
train_loader = DataLoader(dataset, sampler=train_sampler, batch_size=b_size)
validation_loader = DataLoader(dataset, sampler=validation_sampler, batch_size=b_size)
data_loaders = {"train": train_loader, "val": validation_loader}
data_lengths = {"train": len(train_idx), "val": val_len}

real_batch = next(iter(train_loader))
plt.figure(figsize=(8,8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vision_utils.make_grid(real_batch['x'][:4].to(device), padding=2, normalize=True).cpu(),(1,2,0)))

"""### Model"""

random.seed(seed)
torch.manual_seed(seed)
np.random.seed(seed)

netD = initD(3)
netD

"""### Loss and other parameters"""

criterion = nn.BCELoss()

lr = 1e-3
n_epochs = 10
optimizer_D = optim.Adam(netD.parameters(), lr=lr, betas=(0.5, 0.999))

D_train_losses = []
D_valid_losses = []

checkpoint = torch.load('./drive/My Drive/preD-best.pth')
netD.load_state_dict(checkpoint['model_state_dict'])
optimizer_D.load_state_dict(checkpoint['optimizer_state_dict'])
epoch = checkpoint['epoch']

netD.train()

valid_loss_min = np.Inf # track change in validation loss

for epoch in range(1, n_epochs+1):

    # keep track of training and validation loss
    train_loss = 0.0
    valid_loss = 0.0
    
    # train the model #
    netD.train()
    for data in train_loader:
        img = data['x'].cuda()
        target = torch.FloatTensor(data['y'].numpy()).cuda()
        # clear the gradients of all optimized variables
        optimizer_D.zero_grad()
        # forward pass: compute predicted outputs by passing inputs to the model
        output = netD(img)
        # calculate the batch loss
        loss = criterion(output, target)
        # backward pass: compute gradient of the loss with respect to model parameters
        loss.backward()
        # perform a single optimization step (parameter update)
        optimizer_D.step()
        # update training loss
        train_loss += loss.item()*data['x'].size(0)
        
    # Validating the model
    netD.eval()
    for data in validation_loader:
        img = data['x'].cuda()
        target = torch.FloatTensor(data['y'].numpy()).cuda()
        # forward pass: compute predicted outputs by passing inputs to the model
        output = netD(img)
        # calculate the batch loss
        loss = criterion(output, target)
        # update average validation loss 
        valid_loss += loss.item()*data['x'].size(0)
    
    # calculate average losses
    train_loss = train_loss/len(train_loader.dataset)
    valid_loss = valid_loss/len(validation_loader.dataset)
        
    # print training/validation statistics 
    print('Epoch: {} \tTraining Loss: {:.6f} \tValidation Loss: {:.6f}'.format(
        epoch, train_loss, valid_loss))
    
    # save model if validation loss has decreased
    if valid_loss <= valid_loss_min:
        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(
        valid_loss_min,
        valid_loss))
        torch.save({
                'epoch': epoch,
                'model_state_dict':netD.state_dict(),
                'optimizer_state_dict': optimizer_D.state_dict(),
                }, "./drive/My Drive/preD-best.pth")
        valid_loss_min = valid_loss

"""## Upscale (8 x 8)

### Model
"""

netG = addGenLayer(netG, ngf * 8, ngf * 4)
netG

"""### DataLoader"""

random.seed(seed)
torch.manual_seed(seed)
np.random.seed(seed)

dataset = NoiseImageDataset(root=PATH/'img_align_celeba',
                           noise_set=noise_set,
                           transforms_=[
                               transforms.Resize(image_size // 8),
                               transforms.CenterCrop(image_size // 8),
                               transforms.ToTensor(),
                               transforms.Normalize((.5,.5,.5), (.5,.5,.5)),
                           ])

dataloader = DataLoader(dataset, batch_size=b_size, 
                        shuffle=True, num_workers=0)

real_batch = next(iter(dataloader))
plt.figure(figsize=(8,8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vision_utils.make_grid(real_batch['y'].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))

"""### Parameters"""

criterion = nn.L1Loss()

lr = 1e-3
n_epochs = 10
optimizer_G = optim.Adam(netG.parameters(), lr=lr, betas=(0.5, 0.999))
# optimizer_D = optim.Adam(netD.parameters(), lr=lr, betas=(0.5, 0.999))

"""### Memory Allocations"""

G_losses = []
Tensor = torch.cuda.FloatTensor
target = Tensor(b_size, 3, image_size//8, image_size//8)
# input_B = Tensor(b_size, 3, image_size//16, image_size//16)

target_real = Variable(Tensor(b_size).fill_(1.), requires_grad=False)
target_fake = Variable(Tensor(b_size).fill_(0.), requires_grad=False)

"""### Training"""

checkpoint = torch.load('./drive/My Drive/preG-8-final.pth')
netG.load_state_dict(checkpoint['model_state_dict'])
optimizer_G.load_state_dict(checkpoint['optimizer_state_dict'])
epoch = checkpoint['epoch']

netG.train()

import os
import shutil

for e in range(0 , n_epochs):
  for i, batch in enumerate(dataloader):
    
    if(batch['y'].shape[0] != b_size):
      continue

    # Set model inputs
    target_img = Variable(target.copy_(batch['y']))
    inp = batch['x']
    
    optimizer_G.zero_grad()
    
    # L1 Loss
    fake_img = netG(inp)
    loss_G = criterion(fake_img, target_img)
    loss_G.backward()
    
    optimizer_G.step()
    
    
    # Output training stats
    if i % 50 == 0:
        print('[%d/%d][%d/%d]\tLoss_G: %.4f'
#               % (e, n_epochs, i, len(dataloader),
                 loss_G.item()))

    # Save Losses for plotting later
    G_losses.append(loss_G.item())
  
  if e % 5 == 0:
    torch.save({
            'epoch': e,
            'model_state_dict':netG.state_dict(),
            'optimizer_state_dict': optimizer_G.state_dict(),
            }, "./drive/My Drive/preG-8-{}.pth".format(e))

torch.save({
        'epoch': e,
        'model_state_dict':netG.state_dict(),
        'optimizer_state_dict': optimizer_G.state_dict(),
        }, "./drive/My Drive/preG-8-final.pth".format(e))

"""## 8x8 Images (Discriminator)

### Sampling Images
"""

random.seed(seed)
torch.manual_seed(seed)
np.random.seed(seed)

# Sampling fake images
fake_samples = []
for i in range(1, d_len + 1):
  fixed_noise = noise_set[i-1]
  fake = netG(fixed_noise.unsqueeze(0)).detach().cpu().numpy()
  fake_samples.append(fake.squeeze(0))
  if i % 50000 == 0:
    print(i)

"""### DataLoader"""

class DiscrimDataset(Dataset):
  def __init__(self, root, fake_samples, transforms_=None):
    self.transform = transforms.Compose(transforms_)
    
    self.files = sorted(glob.glob(os.path.join(root) + '/*.*'))
    self.fake_samples = fake_samples
    self.len = len(fake_samples)
    
  def __getitem__(self, index):
    rand = np.random.random_sample()
    if rand >= 0.5:
      item = self.transform(Image.open(self.files[index % self.len]))
      return {'x': item, 'y': 1}
    else:
      item = torch.from_numpy(self.fake_samples[index % self.len])
      return {'x': item, 'y': 0}
    
  
  def __len__(self):
    return self.len

dataset = DiscrimDataset(root=PATH/'img_align_celeba',
                           fake_samples=fake_samples,
                           transforms_=[
                               transforms.Resize(image_size // 8),
                               transforms.CenterCrop(image_size // 8),
                               transforms.ToTensor(),
                               transforms.Normalize((.5,.5,.5), (.5,.5,.5)),
                           ])

random.seed(seed)
torch.manual_seed(seed)
np.random.seed(seed)

# train validation split
validation_split = 0.1

dataset_len = len(dataset)
indices = list(range(dataset_len))

# Randomly splitting indices:
val_len = int(np.floor(validation_split * dataset_len))
validation_idx = np.random.choice(indices, size=val_len, replace=False)
train_idx = list(set(indices) - set(validation_idx))

# Samplers
train_sampler = SubsetRandomSampler(train_idx)
validation_sampler = SubsetRandomSampler(validation_idx)

# DataLoader
train_loader = DataLoader(dataset, sampler=train_sampler, batch_size=b_size)
validation_loader = DataLoader(dataset, sampler=validation_sampler, batch_size=b_size)
data_loaders = {"train": train_loader, "val": validation_loader}
data_lengths = {"train": len(train_idx), "val": val_len}

real_batch = next(iter(train_loader))
plt.figure(figsize=(8,8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vision_utils.make_grid(real_batch['x'][:4].to(device), padding=2, normalize=True).cpu(),(1,2,0)))

"""### Model"""

checkpoint = torch.load('./drive/My Drive/preD-best.pth')
netD.load_state_dict(checkpoint['model_state_dict'])
optimizer_D.load_state_dict(checkpoint['optimizer_state_dict'])
epoch = checkpoint['epoch']

netD.train()

random.seed(seed)
torch.manual_seed(seed)
np.random.seed(seed)

netD = addDisLayer(netD, ndf * 4, ndf * 8)
netD

"""### Loss and other parameters"""

criterion = nn.BCELoss()

lr = 1e-3
n_epochs = 10
optimizer_D = optim.Adam(netD.parameters(), lr=lr, betas=(0.5, 0.999))

D_train_losses = []
D_valid_losses = []

valid_loss_min = np.Inf # track change in validation loss

for epoch in range(1, n_epochs+1):

    # keep track of training and validation loss
    train_loss = 0.0
    valid_loss = 0.0
    
    # train the model #
    netD.train()
    for data in train_loader:
        img = data['x'].cuda()
        target = torch.FloatTensor(data['y'].numpy()).cuda()
        # clear the gradients of all optimized variables
        optimizer_D.zero_grad()
        # forward pass: compute predicted outputs by passing inputs to the model
        output = netD(img)
        # calculate the batch loss
        loss = criterion(output, target)
        # backward pass: compute gradient of the loss with respect to model parameters
        loss.backward()
        # perform a single optimization step (parameter update)
        optimizer_D.step()
        # update training loss
        train_loss += loss.item()*data['x'].size(0)
        
    # Validating the model
    netD.eval()
    for data in validation_loader:
        img = data['x'].cuda()
        target = torch.FloatTensor(data['y'].numpy()).cuda()
        # forward pass: compute predicted outputs by passing inputs to the model
        output = netD(img)
        # calculate the batch loss
        loss = criterion(output, target)
        # update average validation loss 
        valid_loss += loss.item()*data['x'].size(0)
    
    # calculate average losses
    train_loss = train_loss/len(train_loader.dataset)
    valid_loss = valid_loss/len(validation_loader.dataset)
        
    # print training/validation statistics 
    print('Epoch: {} \tTraining Loss: {:.6f} \tValidation Loss: {:.6f}'.format(
        epoch, train_loss, valid_loss))
    
    # save model if validation loss has decreased
    if valid_loss <= valid_loss_min:
        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(
        valid_loss_min,
        valid_loss))
        torch.save({
                'epoch': epoch,
                'model_state_dict':netD.state_dict(),
                'optimizer_state_dict': optimizer_D.state_dict(),
                }, "./drive/My Drive/preD-8-best.pth")
        valid_loss_min = valid_loss

checkpoint = torch.load('./drive/My Drive/preD-8-best.pth')
netD.load_state_dict(checkpoint['model_state_dict'])
optimizer_D.load_state_dict(checkpoint['optimizer_state_dict'])
epoch = checkpoint['epoch']

netD.train()



"""## Upscale (16x 16)

### Model
"""

netG = addGenLayer(netG, ngf * 4, ngf * 2)
netG

"""### DataLoader"""

random.seed(seed)
torch.manual_seed(seed)
np.random.seed(seed)

dataset = NoiseImageDataset(root=PATH/'img_align_celeba',
                           noise_set=noise_set,
                           transforms_=[
                               transforms.Resize(image_size // 4),
                               transforms.CenterCrop(image_size // 4),
                               transforms.ToTensor(),
                               transforms.Normalize((.5,.5,.5), (.5,.5,.5)),
                           ])

dataloader = DataLoader(dataset, batch_size=b_size, 
                        shuffle=True, num_workers=0)

real_batch = next(iter(dataloader))
plt.figure(figsize=(8,8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vision_utils.make_grid(real_batch['y'].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))

"""### Parameters"""

criterion = nn.L1Loss()

lr = 1e-3
n_epochs = 10
optimizer_G = optim.Adam(netG.parameters(), lr=lr, betas=(0.5, 0.999))
# optimizer_D = optim.Adam(netD.parameters(), lr=lr, betas=(0.5, 0.999))

"""### Memory Allocations"""

G_losses = []
Tensor = torch.cuda.FloatTensor
target = Tensor(b_size, 3, image_size//4, image_size//4)
# input_B = Tensor(b_size, 3, image_size//16, image_size//16)

target_real = Variable(Tensor(b_size).fill_(1.), requires_grad=False)
target_fake = Variable(Tensor(b_size).fill_(0.), requires_grad=False)

"""### Training"""

import os
import shutil

for e in range(0 , n_epochs):
  for i, batch in enumerate(dataloader):
    
    if(batch['y'].shape[0] != b_size):
      continue

    # Set model inputs
    target_img = Variable(target.copy_(batch['y']))
    inp = batch['x']
    
    optimizer_G.zero_grad()
    
    # L1 Loss
    fake_img = netG(inp)
    loss_G = criterion(fake_img, target_img)
    loss_G.backward()
    
    optimizer_G.step()
    
    
    # Output training stats
    if i % 50 == 0:
        print('[%d/%d][%d/%d]\tLoss_G: %.4f'
#               % (e, n_epochs, i, len(dataloader),
                 loss_G.item()))

    # Save Losses for plotting later
    G_losses.append(loss_G.item())
  
  if e % 5 == 0:
    torch.save({
            'epoch': e,
            'model_state_dict':netG.state_dict(),
            'optimizer_state_dict': optimizer_G.state_dict(),
            }, "./drive/My Drive/preG-16-{}.pth".format(e))

torch.save({
        'epoch': e,
        'model_state_dict':netG.state_dict(),
        'optimizer_state_dict': optimizer_G.state_dict(),
        }, "./drive/My Drive/preG-16-final.pth".format(e))

checkpoint = torch.load('./drive/My Drive/preG-16-final.pth')
netG.load_state_dict(checkpoint['model_state_dict'])
optimizer_G.load_state_dict(checkpoint['optimizer_state_dict'])
epoch = checkpoint['epoch']

netG.train()

"""## 16x16 Images (Discriminator)

### Sampling Images
"""

random.seed(seed)
torch.manual_seed(seed)
np.random.seed(seed)

# Sampling fake images
fake_samples = []
for i in range(1, d_len + 1):
  fixed_noise = noise_set[i-1]
  fake = netG(fixed_noise.unsqueeze(0)).detach().cpu().numpy()
  fake_samples.append(fake.squeeze(0))
  if i % 50000 == 0:
    print(i)

"""### DataLoader"""

class DiscrimDataset(Dataset):
  def __init__(self, root, fake_samples, transforms_=None):
    self.transform = transforms.Compose(transforms_)
    
    self.files = sorted(glob.glob(os.path.join(root) + '/*.*'))
    self.fake_samples = fake_samples
    self.len = len(fake_samples)
    
  def __getitem__(self, index):
    rand = np.random.random_sample()
    if rand >= 0.5:
      item = self.transform(Image.open(self.files[index % self.len]))
      return {'x': item, 'y': 1}
    else:
      item = torch.from_numpy(self.fake_samples[index % self.len])
      return {'x': item, 'y': 0}
    
  
  def __len__(self):
    return self.len

dataset = DiscrimDataset(root=PATH/'img_align_celeba',
                           fake_samples=fake_samples,
                           transforms_=[
                               transforms.Resize(image_size // 4),
                               transforms.CenterCrop(image_size // 4),
                               transforms.ToTensor(),
                               transforms.Normalize((.5,.5,.5), (.5,.5,.5)),
                           ])

random.seed(seed)
torch.manual_seed(seed)
np.random.seed(seed)

# train validation split
validation_split = 0.1

dataset_len = len(dataset)
indices = list(range(dataset_len))

# Randomly splitting indices:
val_len = int(np.floor(validation_split * dataset_len))
validation_idx = np.random.choice(indices, size=val_len, replace=False)
train_idx = list(set(indices) - set(validation_idx))

# Samplers
train_sampler = SubsetRandomSampler(train_idx)
validation_sampler = SubsetRandomSampler(validation_idx)

# DataLoader
train_loader = DataLoader(dataset, sampler=train_sampler, batch_size=b_size)
validation_loader = DataLoader(dataset, sampler=validation_sampler, batch_size=b_size)
data_loaders = {"train": train_loader, "val": validation_loader}
data_lengths = {"train": len(train_idx), "val": val_len}

real_batch = next(iter(train_loader))
plt.figure(figsize=(8,8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vision_utils.make_grid(real_batch['x'][:20].to(device), padding=2, normalize=True).cpu(),(1,2,0)))

real_batch['y'][:20]

"""### Model"""

checkpoint = torch.load('./drive/My Drive/preD-8-best.pth')
netD.load_state_dict(checkpoint['model_state_dict'])
optimizer_D.load_state_dict(checkpoint['optimizer_state_dict'])
epoch = checkpoint['epoch']

netD.train()

random.seed(seed)
torch.manual_seed(seed)
np.random.seed(seed)

netD = addDisLayer(netD, ndf * 2, ndf * 4)
netD

"""### Loss and other parameters"""

criterion = nn.BCELoss()

lr = 1e-3
n_epochs = 5
optimizer_D = optim.Adam(netD.parameters(), lr=lr, betas=(0.5, 0.999))

D_train_losses = []
D_valid_losses = []

valid_loss_min = np.Inf # track change in validation loss

for epoch in range(1, n_epochs+1):

    # keep track of training and validation loss
    train_loss = 0.0
    valid_loss = 0.0
    
    # train the model #
    netD.train()
    for data in train_loader:
        img = data['x'].cuda()
        target = torch.FloatTensor(data['y'].numpy()).cuda()
        # clear the gradients of all optimized variables
        optimizer_D.zero_grad()
        # forward pass: compute predicted outputs by passing inputs to the model
        output = netD(img)
        # calculate the batch loss
        loss = criterion(output, target)
        # backward pass: compute gradient of the loss with respect to model parameters
        loss.backward()
        # perform a single optimization step (parameter update)
        optimizer_D.step()
        # update training loss
        train_loss += loss.item()*data['x'].size(0)
        
    # Validating the model
    netD.eval()
    for data in validation_loader:
        img = data['x'].cuda()
        target = torch.FloatTensor(data['y'].numpy()).cuda()
        # forward pass: compute predicted outputs by passing inputs to the model
        output = netD(img)
        # calculate the batch loss
        loss = criterion(output, target)
        # update average validation loss 
        valid_loss += loss.item()*data['x'].size(0)
    
    # calculate average losses
    train_loss = train_loss/len(train_loader.dataset)
    valid_loss = valid_loss/len(validation_loader.dataset)
        
    # print training/validation statistics 
    print('Epoch: {} \tTraining Loss: {:.6f} \tValidation Loss: {:.6f}'.format(
        epoch, train_loss, valid_loss))
    
    # save model if validation loss has decreased
    if valid_loss <= valid_loss_min:
        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(
        valid_loss_min,
        valid_loss))
        torch.save({
                'epoch': epoch,
                'model_state_dict':netD.state_dict(),
                'optimizer_state_dict': optimizer_D.state_dict(),
                }, "./drive/My Drive/preD-16-best.pth")
        valid_loss_min = valid_loss

checkpoint = torch.load('./drive/My Drive/preD-16-best.pth')
netD.load_state_dict(checkpoint['model_state_dict'])
optimizer_D.load_state_dict(checkpoint['optimizer_state_dict'])
epoch = checkpoint['epoch']

netD.train()

"""## Upscale (32x 32)

### Model
"""

netG = addGenLayer(netG, ngf * 2, ngf * 1)
netG

"""### DataLoader"""

random.seed(seed)
torch.manual_seed(seed)
np.random.seed(seed)

dataset = NoiseImageDataset(root=PATH/'img_align_celeba',
                           noise_set=noise_set,
                           transforms_=[
                               transforms.Resize(image_size // 2),
                               transforms.CenterCrop(image_size // 2),
                               transforms.ToTensor(),
                               transforms.Normalize((.5,.5,.5), (.5,.5,.5)),
                           ])

dataloader = DataLoader(dataset, batch_size=b_size, 
                        shuffle=True, num_workers=0)

real_batch = next(iter(dataloader))
plt.figure(figsize=(8,8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vision_utils.make_grid(real_batch['y'].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))

"""### Parameters"""

criterion = nn.L1Loss()

lr = 1e-3
n_epochs = 10
optimizer_G = optim.Adam(netG.parameters(), lr=lr, betas=(0.5, 0.999))
# optimizer_D = optim.Adam(netD.parameters(), lr=lr, betas=(0.5, 0.999))

"""### Memory Allocations"""

G_losses = []
Tensor = torch.cuda.FloatTensor
target = Tensor(b_size, 3, image_size//2, image_size//2)
# input_B = Tensor(b_size, 3, image_size//16, image_size//16)

target_real = Variable(Tensor(b_size).fill_(1.), requires_grad=False)
target_fake = Variable(Tensor(b_size).fill_(0.), requires_grad=False)

"""### Training"""

import os
import shutil

for e in range(0 , n_epochs):
  for i, batch in enumerate(dataloader):
    
    if(batch['y'].shape[0] != b_size):
      continue

    # Set model inputs
    target_img = Variable(target.copy_(batch['y']))
    inp = batch['x']
    
    optimizer_G.zero_grad()
    
    # L1 Loss
    fake_img = netG(inp)
    loss_G = criterion(fake_img, target_img)
    loss_G.backward()
    
    optimizer_G.step()
    
    
    # Output training stats
    if i % 50 == 0:
        print('[%d/%d][%d/%d]\tLoss_G: %.4f'
#               % (e, n_epochs, i, len(dataloader),
                 loss_G.item()))

    # Save Losses for plotting later
    G_losses.append(loss_G.item())
  
  if e % 5 == 0:
    torch.save({
            'epoch': e,
            'model_state_dict':netG.state_dict(),
            'optimizer_state_dict': optimizer_G.state_dict(),
            }, "./drive/My Drive/preG-32-{}.pth".format(e))

torch.save({
        'epoch': e,
        'model_state_dict':netG.state_dict(),
        'optimizer_state_dict': optimizer_G.state_dict(),
        }, "./drive/My Drive/preG-32-final.pth".format(e))

checkpoint = torch.load('./drive/My Drive/preG-32-final.pth')
netG.load_state_dict(checkpoint['model_state_dict'])
optimizer_G.load_state_dict(checkpoint['optimizer_state_dict'])
epoch = checkpoint['epoch']

netG.train()

"""## 32x32 Images (Discriminator)

### Sampling Images
"""

random.seed(seed)
torch.manual_seed(seed)
np.random.seed(seed)

# Sampling fake images
fake_samples = []
for i in range(1, d_len + 1):
  fixed_noise = noise_set[i-1]
  fake = netG(fixed_noise.unsqueeze(0)).detach().cpu().numpy()
  fake_samples.append(fake.squeeze(0))
  if i % 50000 == 0:
    print(i)

"""### DataLoader"""

class DiscrimDataset(Dataset):
  def __init__(self, root, fake_samples, transforms_=None):
    self.transform = transforms.Compose(transforms_)
    
    self.files = sorted(glob.glob(os.path.join(root) + '/*.*'))
    self.fake_samples = fake_samples
    self.len = len(fake_samples)
    
  def __getitem__(self, index):
    rand = np.random.random_sample()
    if rand >= 0.5:
      item = self.transform(Image.open(self.files[index % self.len]))
      return {'x': item, 'y': 1}
    else:
      item = torch.from_numpy(self.fake_samples[index % self.len])
      return {'x': item, 'y': 0}
    
  
  def __len__(self):
    return self.len

dataset = DiscrimDataset(root=PATH/'img_align_celeba',
                           fake_samples=fake_samples,
                           transforms_=[
                               transforms.Resize(image_size // 2),
                               transforms.CenterCrop(image_size // 2),
                               transforms.ToTensor(),
                               transforms.Normalize((.5,.5,.5), (.5,.5,.5)),
                           ])

random.seed(seed)
torch.manual_seed(seed)
np.random.seed(seed)

# train validation split
validation_split = 0.1

dataset_len = len(dataset)
indices = list(range(dataset_len))

# Randomly splitting indices:
val_len = int(np.floor(validation_split * dataset_len))
validation_idx = np.random.choice(indices, size=val_len, replace=False)
train_idx = list(set(indices) - set(validation_idx))

# Samplers
train_sampler = SubsetRandomSampler(train_idx)
validation_sampler = SubsetRandomSampler(validation_idx)

# DataLoader
train_loader = DataLoader(dataset, sampler=train_sampler, batch_size=b_size)
validation_loader = DataLoader(dataset, sampler=validation_sampler, batch_size=b_size)
data_loaders = {"train": train_loader, "val": validation_loader}
data_lengths = {"train": len(train_idx), "val": val_len}

real_batch = next(iter(train_loader))
plt.figure(figsize=(8,8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vision_utils.make_grid(real_batch['x'][:20].to(device), padding=2, normalize=True).cpu(),(1,2,0)))

real_batch['y'][:20]

"""### Model"""

checkpoint = torch.load('./drive/My Drive/preD-16-best.pth')
netD.load_state_dict(checkpoint['model_state_dict'])
optimizer_D.load_state_dict(checkpoint['optimizer_state_dict'])
epoch = checkpoint['epoch']

netD.train()

random.seed(seed)
torch.manual_seed(seed)
np.random.seed(seed)

netD = addDisLayer(netD, ndf * 1, ndf * 2)
netD

"""### Loss and other parameters"""

criterion = nn.BCELoss()

lr = 1e-3
n_epochs = 5
optimizer_D = optim.Adam(netD.parameters(), lr=lr, betas=(0.5, 0.999))

D_train_losses = []
D_valid_losses = []

valid_loss_min = np.Inf # track change in validation loss

for epoch in range(1, n_epochs+1):

    # keep track of training and validation loss
    train_loss = 0.0
    valid_loss = 0.0
    
    # train the model #
    netD.train()
    for data in train_loader:
        img = data['x'].cuda()
        target = torch.FloatTensor(data['y'].numpy()).cuda()
        # clear the gradients of all optimized variables
        optimizer_D.zero_grad()
        # forward pass: compute predicted outputs by passing inputs to the model
        output = netD(img)
        # calculate the batch loss
        loss = criterion(output, target)
        # backward pass: compute gradient of the loss with respect to model parameters
        loss.backward()
        # perform a single optimization step (parameter update)
        optimizer_D.step()
        # update training loss
        train_loss += loss.item()*data['x'].size(0)
        
    # Validating the model
    netD.eval()
    for data in validation_loader:
        img = data['x'].cuda()
        target = torch.FloatTensor(data['y'].numpy()).cuda()
        # forward pass: compute predicted outputs by passing inputs to the model
        output = netD(img)
        # calculate the batch loss
        loss = criterion(output, target)
        # update average validation loss 
        valid_loss += loss.item()*data['x'].size(0)
    
    # calculate average losses
    train_loss = train_loss/len(train_loader.dataset)
    valid_loss = valid_loss/len(validation_loader.dataset)
        
    # print training/validation statistics 
    print('Epoch: {} \tTraining Loss: {:.6f} \tValidation Loss: {:.6f}'.format(
        epoch, train_loss, valid_loss))
    
    # save model if validation loss has decreased
    if valid_loss <= valid_loss_min:
        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(
        valid_loss_min,
        valid_loss))
        torch.save({
                'epoch': epoch,
                'model_state_dict':netD.state_dict(),
                'optimizer_state_dict': optimizer_D.state_dict(),
                }, "./drive/My Drive/preD-32-best.pth")
        valid_loss_min = valid_loss

checkpoint = torch.load('./drive/My Drive/preD-32-best.pth')
netD.load_state_dict(checkpoint['model_state_dict'])
optimizer_D.load_state_dict(checkpoint['optimizer_state_dict'])
epoch = checkpoint['epoch']

netD.train()



"""## Upscale (64x 64)

### Model
"""

netG = addGenLayer(netG, ngf * 1, ngf * 1)
netG

"""### DataLoader"""

random.seed(seed)
torch.manual_seed(seed)
np.random.seed(seed)

dataset = NoiseImageDataset(root=PATH/'img_align_celeba',
                           noise_set=noise_set,
                           transforms_=[
                               transforms.Resize(image_size // 1),
                               transforms.CenterCrop(image_size // 1),
                               transforms.ToTensor(),
                               transforms.Normalize((.5,.5,.5), (.5,.5,.5)),
                           ])

dataloader = DataLoader(dataset, batch_size=b_size, 
                        shuffle=True, num_workers=0)

real_batch = next(iter(dataloader))
plt.figure(figsize=(8,8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vision_utils.make_grid(real_batch['y'].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))

"""### Parameters"""

criterion = nn.L1Loss()

lr = 1e-3
n_epochs = 10
optimizer_G = optim.Adam(netG.parameters(), lr=lr, betas=(0.5, 0.999))
# optimizer_D = optim.Adam(netD.parameters(), lr=lr, betas=(0.5, 0.999))

"""### Memory Allocations"""

G_losses = []
Tensor = torch.cuda.FloatTensor
target = Tensor(b_size, 3, image_size//1, image_size//1)
# input_B = Tensor(b_size, 3, image_size//16, image_size//16)

target_real = Variable(Tensor(b_size).fill_(1.), requires_grad=False)
target_fake = Variable(Tensor(b_size).fill_(0.), requires_grad=False)

"""### Training"""

import os
import shutil

for e in range(0 , n_epochs):
  for i, batch in enumerate(dataloader):
    
    if(batch['y'].shape[0] != b_size):
      continue

    # Set model inputs
    target_img = Variable(target.copy_(batch['y']))
    inp = batch['x']
    
    optimizer_G.zero_grad()
    
    # L1 Loss
    fake_img = netG(inp)
    loss_G = criterion(fake_img, target_img)
    loss_G.backward()
    
    optimizer_G.step()
    
    
    # Output training stats
    if i % 50 == 0:
        print('[%d/%d][%d/%d]\tLoss_G: %.4f'
#               % (e, n_epochs, i, len(dataloader),
                 loss_G.item()))

    # Save Losses for plotting later
    G_losses.append(loss_G.item())
  
  if e % 5 == 0:
    torch.save({
            'epoch': e,
            'model_state_dict':netG.state_dict(),
            'optimizer_state_dict': optimizer_G.state_dict(),
            }, "./drive/My Drive/preG-64-{}.pth".format(e))

torch.save({
        'epoch': e,
        'model_state_dict':netG.state_dict(),
        'optimizer_state_dict': optimizer_G.state_dict(),
        }, "./drive/My Drive/preG-64-final.pth".format(e))

checkpoint = torch.load('./drive/My Drive/preG-64-final.pth')
netG.load_state_dict(checkpoint['model_state_dict'])
optimizer_G.load_state_dict(checkpoint['optimizer_state_dict'])
epoch = checkpoint['epoch']

netG.eval()

"""## 64x64 Images (Discriminator)

### Sampling Images
"""

random.seed(seed)
torch.manual_seed(seed)
np.random.seed(seed)

# Sampling fake images
fake_samples = []
for i in range(1, d_len + 1):
  fixed_noise = noise_set[i-1]
  fake = netG(fixed_noise.unsqueeze(0)).detach().cpu().numpy()
  fake_samples.append(fake.squeeze(0))
  if i % 50000 == 0:
    print(i)

"""### DataLoader"""

l = len(fake_samples)
l

class DiscrimDataset(Dataset):
  def __init__(self, root, fake_samples, transforms_=None):
    self.transform = transforms.Compose(transforms_)
    
    self.files = sorted(glob.glob(os.path.join(root) + '/*.*'))
    self.fake_samples = fake_samples
    self.l = len(fake_samples)
    self.len = len(self.files)
    
  def __getitem__(self, index):
    rand = np.random.random_sample()
    if rand >= 0.5:
      item = self.transform(Image.open(self.files[index % self.len]))
      return {'x': item, 'y': 1}
    else:
      item = torch.from_numpy(self.fake_samples[index % self.l])
      return {'x': item, 'y': 0}
    
  
  def __len__(self):
    return self.len

dataset = DiscrimDataset(root=PATH/'img_align_celeba',
                           fake_samples=fake_samples,
                           transforms_=[
                               transforms.Resize(image_size // 1),
                               transforms.CenterCrop(image_size // 1),
                               transforms.ToTensor(),
                               transforms.Normalize((.5,.5,.5), (.5,.5,.5)),
                           ])

random.seed(seed)
torch.manual_seed(seed)
np.random.seed(seed)

# train validation split
validation_split = 0.1

dataset_len = len(dataset)
indices = list(range(dataset_len))

# Randomly splitting indices:
val_len = int(np.floor(validation_split * dataset_len))
validation_idx = np.random.choice(indices, size=val_len, replace=False)
train_idx = list(set(indices) - set(validation_idx))

# Samplers
train_sampler = SubsetRandomSampler(train_idx)
validation_sampler = SubsetRandomSampler(validation_idx)

# DataLoader
train_loader = DataLoader(dataset, sampler=train_sampler, batch_size=b_size)
validation_loader = DataLoader(dataset, sampler=validation_sampler, batch_size=b_size)
data_loaders = {"train": train_loader, "val": validation_loader}
data_lengths = {"train": len(train_idx), "val": val_len}

real_batch = next(iter(train_loader))
plt.figure(figsize=(8,8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vision_utils.make_grid(real_batch['x'][:20].to(device), padding=2, normalize=True).cpu(),(1,2,0)))

real_batch['y'][:20]

"""### Model"""

checkpoint = torch.load('./drive/My Drive/preD-32-best.pth')
netD.load_state_dict(checkpoint['model_state_dict'])
optimizer_D.load_state_dict(checkpoint['optimizer_state_dict'])
epoch = checkpoint['epoch']

netD.train()

random.seed(seed)
torch.manual_seed(seed)
np.random.seed(seed)

netD = addDisLayer(netD, ndf // 2, ndf * 1)
netD

"""### Loss and other parameters"""

criterion = nn.BCELoss()

lr = 1e-3
n_epochs = 20
optimizer_D = optim.Adam(netD.parameters(), lr=lr, betas=(0.5, 0.999))

D_train_losses = []
D_valid_losses = []

valid_loss_min = np.Inf # track change in validation loss

for epoch in range(1, n_epochs+1):

    # keep track of training and validation loss
    train_loss = 0.0
    valid_loss = 0.0
    
    # train the model #
    netD.train()
    for data in train_loader:
        img = data['x'].cuda()
        target = torch.FloatTensor(data['y'].numpy()).cuda()
        # clear the gradients of all optimized variables
        optimizer_D.zero_grad()
        # forward pass: compute predicted outputs by passing inputs to the model
        output = netD(img)
        # calculate the batch loss
        loss = 0.5 * ((output - target)**2).mean().view(1)
        # backward pass: compute gradient of the loss with respect to model parameters
        loss.backward()
        # perform a single optimization step (parameter update)
        optimizer_D.step()
        # update training loss
        train_loss += loss.item()*data['x'].size(0)
        
    # Validating the model
    netD.eval()
    for data in validation_loader:
        img = data['x'].cuda()
        target = torch.FloatTensor(data['y'].numpy()).cuda()
        # forward pass: compute predicted outputs by passing inputs to the model
        output = netD(img)
        # calculate the batch loss
        loss = 0.5 * ((output - target)**2).mean().view(1)
        # update average validation loss 
        valid_loss += loss.item()*data['x'].size(0)
    
    # calculate average losses
    train_loss = train_loss/len(train_loader.dataset)
    valid_loss = valid_loss/len(validation_loader.dataset)
        
    # print training/validation statistics 
    print('Epoch: {} \tTraining Loss: {:.6f} \tValidation Loss: {:.6f}'.format(
        epoch, train_loss, valid_loss))
    
    # save model if validation loss has decreased
    if valid_loss <= valid_loss_min:
        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(
        valid_loss_min,
        valid_loss))
        torch.save({
                'epoch': epoch,
                'model_state_dict':netD.state_dict(),
                'optimizer_state_dict': optimizer_D.state_dict(),
                }, "./drive/My Drive/preD-64-best.pth")
        valid_loss_min = valid_loss

checkpoint = torch.load('./drive/My Drive/preD-64-best.pth')
netD.load_state_dict(checkpoint['model_state_dict'])
optimizer_D.load_state_dict(checkpoint['optimizer_state_dict'])
epoch = checkpoint['epoch']

netD.train()

# Sampling fake images
fake_samples = []



"""# GAN Training

## DataLoader
"""

dataset = dset.ImageFolder(root=PATH,
                           transform=transforms.Compose([
                               transforms.Resize(image_size),
                               transforms.CenterCrop(image_size),
                               transforms.ToTensor(),
                               transforms.Normalize((.5,.5,.5), (.5,.5,.5)),
                           ]))
  
dataloader = DataLoader(dataset, batch_size=b_size, 
                        shuffle=True, num_workers=workers)

random.seed(seed)
torch.manual_seed(seed)
np.random.seed(seed)

real_batch = next(iter(dataloader))
plt.figure(figsize=(8,8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vision_utils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))

"""## Model

## Params and LR
"""

random.seed(seed)
torch.manual_seed(seed)
np.random.seed(seed)

def get_infinite_batches(data_loader):
  while True:
      for i, (images, _) in enumerate(data_loader):
          yield images

fixed_noise_1 = torch.randn(64, nz, 1, 1, device=device)

real_label = 1
fake_label = 0

lr_G = 4e-4
lr_D = 3e-4
optimizer_D = optim.Adam(netD.parameters(), lr=lr_D, betas=(0.5, 0.999))
optimizer_G = optim.Adam(netG.parameters(), lr=lr_G, betas=(0.5, 0.999))

b_size = 128

max_iters = 60000
weight_clip = 0.01
gen_iters = 2
crit_iters = 1

# Lists to keep track of progress
img_list = []
G_losses = []
C_losses_fake = []
C_losses_real = []
C_losses = []
diff_G_loss = []
diff_C_loss = []
real_C_res = np.ndarray(max_iters * b_size + 1, dtype=np.float16)
fake_C_res = np.ndarray(max_iters * b_size + 1, dtype=np.float16)

one = torch.FloatTensor([1])
mone = one * -1
one = one.cuda()
m_one = mone.cuda()

Tensor = torch.cuda.FloatTensor
target_real = Variable(Tensor(b_size).fill_(1.), requires_grad=False)
target_fake = Variable(Tensor(b_size).fill_(0.), requires_grad=False)

data = get_infinite_batches(dataloader)

checkpoint = torch.load('./drive/My Drive/netD-GAN-40000.pth')
netD.load_state_dict(checkpoint['model_state_dict'])
optimizer_D.load_state_dict(checkpoint['optimizer_state_dict'])
epoch = checkpoint['epoch']

netD.train()

checkpoint = torch.load('./drive/My Drive/netG-GAN-40000.pth')
netG.load_state_dict(checkpoint['model_state_dict'])
optimizer_G.load_state_dict(checkpoint['optimizer_state_dict'])
epoch = checkpoint['epoch']

netD.train()

netG.train()
netD.train()

for i in range(1, max_iters + 1):
  
  # Since, Critic will be updated first.
  for p in netD.parameters():
    p.requires_grad = True
    
  C_loss = 0.
  for j in range(1, crit_iters + 1):
    # Update Critic network.
      
    netD.zero_grad()
        
    # Sample data from real distribution
    real_data = next(data).cuda()
    
    # Sample data from fake distribution
    noise = torch.randn(b_size, nz, 1, 1, device=device)
    fake_data = netG(noise) 
    
    # Getting the outputs of Critic
    C_real = netD(real_data)
    C_fake = netD(fake_data.detach()) # To remove it from the graph
    
    # Finding the errors
    C_loss_real = 0.5 * ((C_real - 1.0)**2).mean().view(1) # mean along rows
    C_loss_real.backward()
    
    C_loss_fake = 0.5 * ((C_fake - 0.0)**2).mean().view(1)
    C_loss_fake.backward()
    
    
    C_loss = C_loss_fake + C_loss_real # -V(D,G)
#     Wasserstein_D = -(C_loss_fake / (1 - alpha(i, max_iters, 0.5))  + C_loss_real)
    optimizer_D.step()
    
    # Clip the weights of Critic network
#     for p in netC.parameters():
#       p.data.clamp_(-weight_clip, weight_clip)
      
    # Getting real_critic_results
#     if (j % crit_iters == (crit_iters - 1)):
#       if len(real_data) == b_size:
#         for k in range(b_size):
#           real_C_res[b_size * i + k] = C_real[k]
#       else:
#         real_data1 = next(data).cuda()
#         C_real1 = netC(real_data1)
#         for k in range(b_size):
#           real_C_res[b_size * i + k] = C_real1[k]
  
  G_loss = 0.    
  # Update Generator network.
  for p in netD.parameters():
     p.requires_grad = False  # to avoid computation

  for j in range(1, gen_iters + 1):
    # Update Generator network.
    netG.zero_grad()

    # Sample data from fake distribution
    noise = torch.randn(b_size, nz, 1, 1, device=device)
    fake_data = netG(noise)

    # Finding the error
    C_G_noise = netD(fake_data)
    G_loss = 0.5 * ((C_G_noise - 1.0)**2).mean().view(1)
    G_loss.backward()
    G_cost = G_loss
    optimizer_G.step()
    
    # Getting fake_critic_results
#     for k in range(b_size):
#         fake_C_res[b_size * i + k] = C_G_noise[k]
    
    
    
  # Display Results
  if i % 10 == 0:
    print('[%d/%d]\tLoss_C: %.4f\tLoss_C_fake: %.4f\tLoss_C_real: %.4f\tLoss_G: %.4f\t'
#         % (i, max_iters, C_loss.item(), C_loss_fake.item(), C_loss_real.item(), G_loss.item()))

  # Save Losses for plotting later
  G_losses.append(G_loss.item())
  C_losses.append(C_loss.item())  
  C_losses_fake.append(C_loss_fake.item())
  C_losses_real.append(C_loss_real.item())
  
#   if (i > 1):
#     diff_G_loss.append(G_losses[i-1] - G_losses[i-2])
#     diff_C_loss.append(C_losses[i-1] - C_losses[i-2])

  # Display images
  # Check how the generator is doing by saving G's output on fixed_noise
  if (i % 250 == 0):
    with torch.no_grad():
       fake = netG(fixed_noise_1).detach().cpu()
    img_list.append(vision_utils.make_grid(fake, padding=2, normalize=True))
    plt.imshow(np.transpose(vision_utils.make_grid(img_list[-1].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))
    
  if i % 5000 == 0:
    torch.save({
            'epoch': i,
            'model_state_dict':netD.state_dict(),
            'optimizer_state_dict': optimizer_D.state_dict(),
            }, "./drive/My Drive/netD-GAN-{}.pth".format(i))
    
    torch.save({
            'epoch': i,
            'model_state_dict':netG.state_dict(),
            'optimizer_state_dict': optimizer_G.state_dict(),
            }, "./drive/My Drive/netG-GAN-{}.pth".format(i))

import matplotlib.animation as animation
from IPython.display import HTML

#%%capture
fig = plt.figure(figsize=(8,8))
plt.axis("off")
ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list[-20:]]
ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)

HTML(ani.to_jshtml())

netG.eval()
# netG.train()
# Sampling fake images

fixed_noise = noise_set[234]
fake = netG(fixed_noise.unsqueeze(0)).detach().cpu().numpy()
plt.imshow(np.transpose(vision_utils.make_grid(torch.from_numpy(fake).to(device), padding=2, normalize=True).cpu(),(1,2,0)))

netG.eval()
# netG.train()
# Sampling fake images

fixed_noise = noise_set[8735]
fake = netG(fixed_noise.unsqueeze(0)).detach().cpu().numpy()
plt.imshow(np.transpose(vision_utils.make_grid(torch.from_numpy(fake).to(device), padding=2, normalize=True).cpu(),(1,2,0)))

netG.eval()
# netG.train()
# Sampling fake images

fixed_noise = noise_set[785]
fake = netG(fixed_noise.unsqueeze(0)).detach().cpu().numpy()
plt.imshow(np.transpose(vision_utils.make_grid(torch.from_numpy(fake).to(device), padding=2, normalize=True).cpu(),(1,2,0)))

netG.eval()
# netG.train()
# Sampling fake images

fixed_noise = noise_set[11111]
fake = netG(fixed_noise.unsqueeze(0)).detach().cpu().numpy()
plt.imshow(np.transpose(vision_utils.make_grid(torch.from_numpy(fake).to(device), padding=2, normalize=True).cpu(),(1,2,0)))

netG.eval()
# netG.train()
# Sampling fake images

fixed_noise = noise_set[200000]
fake = netG(fixed_noise.unsqueeze(0)).detach().cpu().numpy()
plt.imshow(np.transpose(vision_utils.make_grid(torch.from_numpy(fake).to(device), padding=2, normalize=True).cpu(),(1,2,0)))

netG.eval()
# netG.train()
# Sampling fake images

fixed_noise = noise_set[78500]
fake = netG(fixed_noise.unsqueeze(0)).detach().cpu().numpy()
plt.imshow(np.transpose(vision_utils.make_grid(torch.from_numpy(fake).to(device), padding=2, normalize=True).cpu(),(1,2,0)))

#%%capture
fig = plt.figure(figsize=(16,16))
plt.axis("off")
ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list[-5:]]
ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)

HTML(ani.to_jshtml())

fixed_noise_1 = torch.randn(64, nz, 1, 1, device=device)
fig = plt.figure(figsize=(16,16))
fake = netG(fixed_noise_1).detach().cpu()
plt.imshow(np.transpose(vision_utils.make_grid(fake.to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))

fixed_noise_1 = torch.randn(64, nz, 1, 1, device=device)
fig = plt.figure(figsize=(16,16))
fake = netG(fixed_noise_1).detach().cpu()
plt.imshow(np.transpose(vision_utils.make_grid(fake.to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))

fixed_noise_1 = torch.randn(64, nz, 1, 1, device=device)
fig = plt.figure(figsize=(16,16))
fake = netG(fixed_noise_1).detach().cpu()
plt.imshow(np.transpose(vision_utils.make_grid(fake.to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))

netG.eval()
# netG.train()
# Sampling fake images
fig = plt.figure(figsize=(16,16))

fixed_noise = noise_set[6800:6864]
fake = netG(fixed_noise).detach().cpu()
plt.imshow(np.transpose(vision_utils.make_grid(fake.to(device), padding=2, normalize=True).cpu(),(1,2,0)))

torch.save(netD.state_dict(), "./netD-gan-final.pth".format(i))
torch.save(netG.state_dict(), "./netG-gan-final.pth".format(i))
shutil.copy("./netD-gan-final.pth".format(i), './drive/My Drive/')
shutil.copy("./netG-gan-final.pth".format(i), './drive/My Drive/')

np.save('gan-G_losses.npy', np.array(G_losses))
np.save('gan-C_losses.npy', np.array(C_losses))
np.save('gan-C_losses_fake.npy', C_losses_fake)
np.save('gan-C_losses_real.npy', C_losses_real)

shutil.copy('gan-G_losses.npy', './drive/My Drive/')
shutil.copy('gan-C_losses.npy', './drive/My Drive/')
shutil.copy('gan-C_losses_real.npy', './drive/My Drive/')
shutil.copy('gan-C_losses_fake.npy', './drive/My Drive/')

for i in range(len(img_list)):
  img_list[i] = img_list[i].numpy()

np.save('gan-img_list.npy', img_list)
shutil.copy('gan-img_list.npy', './drive/My Drive/')

